{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minor Project Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhoUPIzQ9-K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99e4ea3-7014-49c2-80cb-f85599cd9076"
      },
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.7)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bVcZ0EU_LoE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7g6sUQr_mkj"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CutJSOIrB3Nd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "15c2e2d4-18ef-4a9f-e050-3c3fb289b30c"
      },
      "source": [
        "filename = (\"/content/drive/MyDrive/Minor Project/Sound.wav\")\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# Displays wave form of data and sample rate recieved \n",
        "data , sample_rate = librosa.load(filename)\n",
        "librosa.display.waveplot(data , sr = sample_rate)  #LIBROSA CONVERTS SIGNAL INTO MONO CHANNEL i.e. single channel\n",
        "#PLays audio\n",
        "ipd.Audio(filename)\n",
        "\n",
        " \n",
        "print(sample_rate)\n",
        "print(data)\n",
        "\n",
        "\n",
        "#Sample_rate = The sampling rate refers to the number of samples of audio recorded every second. \n",
        "#It is measured in samples per second or Hertz (abbreviated as Hz or kHz, with one kHz being 1000 Hz). \n",
        "#An audio sample is just a number representing the measured acoustic wave value at a specific point in time"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22050\n",
            "[ 0.          0.          0.         ...  0.00036545  0.00025941\n",
            " -0.00021183]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Av3MQEC4zR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5924ca07-1e51-48f2-eb76-bcc0a891129f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "metadata = pd.read_csv(\"/content/drive/MyDrive/Minor Project/UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
        "print(metadata)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         slice_file_name    fsID       start  ...  fold  classID             class\n",
            "0       100032-3-0-0.wav  100032    0.000000  ...     5        3          dog_bark\n",
            "1     100263-2-0-117.wav  100263   58.500000  ...     5        2  children_playing\n",
            "2     100263-2-0-121.wav  100263   60.500000  ...     5        2  children_playing\n",
            "3     100263-2-0-126.wav  100263   63.000000  ...     5        2  children_playing\n",
            "4     100263-2-0-137.wav  100263   68.500000  ...     5        2  children_playing\n",
            "...                  ...     ...         ...  ...   ...      ...               ...\n",
            "8727     99812-1-2-0.wav   99812  159.522205  ...     7        1          car_horn\n",
            "8728     99812-1-3-0.wav   99812  181.142431  ...     7        1          car_horn\n",
            "8729     99812-1-4-0.wav   99812  242.691902  ...     7        1          car_horn\n",
            "8730     99812-1-5-0.wav   99812  253.209850  ...     7        1          car_horn\n",
            "8731     99812-1-6-0.wav   99812  332.289233  ...     7        1          car_horn\n",
            "\n",
            "[8732 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmWsRt1sHduv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0b0c6a5-bc9c-48d7-bbf0-04c011e67e5a"
      },
      "source": [
        " '''\n",
        " DATA = metadata.head(20)\n",
        " DATA.iloc[1]['start']\n",
        " '''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nDATA = metadata.head(20)\\nDATA.iloc[1]['start']\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EKRFrGoIKgm"
      },
      "source": [
        "\n",
        "def features_extractor(file):\n",
        "  #filename = \"/content/drive/MyDrive/Minor Project/UrbanSound8K/audio/fold{}/{}\".format(metadata.iloc[i][\"fold\"],metadata.iloc[i][\"slice_file_name\"])\n",
        "  data,sr = librosa.load(filename , res_type='kaiser_fast')\n",
        "  mfccs_features = librosa.feature.mfcc(y = data , sr=sr , n_mfcc=40)\n",
        "  mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "  return mfccs_scaled_features\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gus1sM67KkyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47ccc0b-5aab-40d9-a549-3fb2a9c31498"
      },
      "source": [
        "import numpy as np \n",
        "import os as os\n",
        "from tqdm import tqdm\n",
        "extracted_features = []\n",
        "for index_num,row in tqdm(metadata.iterrows()):\n",
        "  filename = os.path.join(os.path.abspath(\"/content/drive/MyDrive/Minor Project/UrbanSound8K/audio/\"),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "  final_class_labels= row[\"class\"]\n",
        "  data=features_extractor(filename)\n",
        "  extracted_features.append([data,final_class_labels])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3555it [37:25,  1.47it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
            "  n_fft, y.shape[-1]\n",
            "8326it [1:32:59,  1.64it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
            "  n_fft, y.shape[-1]\n",
            "8329it [1:33:01,  1.61it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
            "  n_fft, y.shape[-1]\n",
            "8732it [1:37:42,  1.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdAeATLNnRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5dfd9b-8158-4dc3-a13d-1fe971e71309"
      },
      "source": [
        "Data = pd.DataFrame(extracted_features,columns=[\"Features\",\"Class\"])\n",
        "Features = np.array(Data[\"Features\"].tolist())\n",
        "\n",
        "Class = np.array(Data[\"Class\"].tolist())\n",
        "print(Features)\n",
        "\n",
        "print(Class)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-2.15793015e+02  7.16661224e+01 -1.31813766e+02 ... -1.68275905e+00\n",
            "  -8.85858238e-01  3.54388624e-01]\n",
            " [-4.24686768e+02  1.10562271e+02 -5.41482353e+01 ...  6.17408633e-01\n",
            "  -6.84974074e-01  5.71514428e-01]\n",
            " [-4.59564667e+02  1.22800354e+02 -4.79247093e+01 ...  2.22541404e+00\n",
            "   1.54661798e+00 -8.36315691e-01]\n",
            " ...\n",
            " [-3.04613159e+02  1.12619904e+02 -4.71619453e+01 ... -3.03358078e+00\n",
            "   2.71057296e+00  7.67189503e+00]\n",
            " [-3.44714233e+02  1.26758141e+02 -5.61771698e+01 ... -7.80225849e+00\n",
            "  -1.77907360e+00  5.83541918e+00]\n",
            " [-3.15933838e+02  9.56758881e+01 -3.80477676e+01 ...  5.77580512e-01\n",
            "  -1.14637651e+01 -5.96535349e+00]]\n",
            "['dog_bark' 'children_playing' 'children_playing' ... 'car_horn'\n",
            " 'car_horn' 'car_horn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM-uVZCuN0ya"
      },
      "source": [
        "Class_ = pd.get_dummies(Class)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk_KUweEN3fp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(Features,Class_,train_size=0.2,random_state=0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plJIHz5POaES",
        "outputId": "6def4536-4321-4ab6-8f30-668f8b7acd89"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.0633170e+02  1.4802086e+02 -1.5899812e+01 ... -5.1457338e+00\n",
            "  -4.2918172e+00 -5.6642246e+00]\n",
            " [-3.3058130e+02  2.4216910e+02 -2.2019115e+01 ...  1.1878932e-01\n",
            "  -7.4800295e-01 -3.6139092e-01]\n",
            " [-5.4307560e+01 -8.5185671e+00 -4.9616684e+01 ... -5.4808997e-02\n",
            "  -8.8522464e-01  2.6737165e+00]\n",
            " ...\n",
            " [-4.2699329e+02  9.2890648e+01  3.0233369e+00 ...  8.6335993e-01\n",
            "   6.4766800e-01  7.8490508e-01]\n",
            " [-1.4607024e+02  1.3709459e+02 -3.4298344e+01 ...  1.3777871e+00\n",
            "  -1.9530842e+00 -8.9652115e-01]\n",
            " [-4.2167450e+02  2.1169032e+02  2.6820304e+00 ... -5.1484952e+00\n",
            "  -3.6400859e+00 -1.3321606e+00]]       air_conditioner  car_horn  ...  siren  street_music\n",
            "6655                0         0  ...      0             0\n",
            "5400                1         0  ...      0             0\n",
            "1546                0         0  ...      0             0\n",
            "1335                1         0  ...      0             0\n",
            "6385                0         0  ...      1             0\n",
            "...               ...       ...  ...    ...           ...\n",
            "4373                0         0  ...      0             0\n",
            "7891                1         0  ...      0             0\n",
            "4859                0         0  ...      0             0\n",
            "3264                1         0  ...      0             0\n",
            "2732                0         0  ...      1             0\n",
            "\n",
            "[1746 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "vv3zXYs8OotR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "ez2w8-MLP8wQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ZDcU_uRHVj",
        "outputId": "f1e570d5-8d68-482f-967d-c240001fb26e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 100)               4100      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 200)               20200     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,410\n",
            "Trainable params: 45,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
        "## Trianing my model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 110\n",
        "num_batch_size = 16\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpEQ5edxRJtu",
        "outputId": "2573bdeb-acd8-4e7d-f37a-35318be4965e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7892 - accuracy: 0.7459\n",
            "Epoch 00001: val_loss improved from inf to 0.98939, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 12ms/step - loss: 0.7862 - accuracy: 0.7474 - val_loss: 0.9894 - val_accuracy: 0.7276\n",
            "Epoch 2/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7845 - accuracy: 0.7447\n",
            "Epoch 00002: val_loss improved from 0.98939 to 0.97982, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7810 - accuracy: 0.7446 - val_loss: 0.9798 - val_accuracy: 0.7267\n",
            "Epoch 3/110\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.8296 - accuracy: 0.7392\n",
            "Epoch 00003: val_loss improved from 0.97982 to 0.94167, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.8134 - accuracy: 0.7440 - val_loss: 0.9417 - val_accuracy: 0.7352\n",
            "Epoch 4/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7965 - accuracy: 0.7523\n",
            "Epoch 00004: val_loss did not improve from 0.94167\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7942 - accuracy: 0.7532 - val_loss: 0.9693 - val_accuracy: 0.7199\n",
            "Epoch 5/110\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.7297 - accuracy: 0.7728\n",
            "Epoch 00005: val_loss improved from 0.94167 to 0.93972, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7354 - accuracy: 0.7721 - val_loss: 0.9397 - val_accuracy: 0.7317\n",
            "Epoch 6/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7684 - accuracy: 0.7583\n",
            "Epoch 00006: val_loss improved from 0.93972 to 0.93129, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7694 - accuracy: 0.7589 - val_loss: 0.9313 - val_accuracy: 0.7230\n",
            "Epoch 7/110\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.7623 - accuracy: 0.7520\n",
            "Epoch 00007: val_loss improved from 0.93129 to 0.92145, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7687 - accuracy: 0.7520 - val_loss: 0.9214 - val_accuracy: 0.7325\n",
            "Epoch 8/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.8218 - accuracy: 0.7361\n",
            "Epoch 00008: val_loss did not improve from 0.92145\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.8252 - accuracy: 0.7360 - val_loss: 0.9530 - val_accuracy: 0.7249\n",
            "Epoch 9/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.8150 - accuracy: 0.7390\n",
            "Epoch 00009: val_loss did not improve from 0.92145\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.8153 - accuracy: 0.7383 - val_loss: 0.9391 - val_accuracy: 0.7300\n",
            "Epoch 10/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7914 - accuracy: 0.7345\n",
            "Epoch 00010: val_loss did not improve from 0.92145\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7822 - accuracy: 0.7365 - val_loss: 0.9493 - val_accuracy: 0.7333\n",
            "Epoch 11/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7514 - accuracy: 0.7655\n",
            "Epoch 00011: val_loss did not improve from 0.92145\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7524 - accuracy: 0.7652 - val_loss: 0.9252 - val_accuracy: 0.7293\n",
            "Epoch 12/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7804 - accuracy: 0.7552\n",
            "Epoch 00012: val_loss did not improve from 0.92145\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7800 - accuracy: 0.7549 - val_loss: 0.9463 - val_accuracy: 0.7319\n",
            "Epoch 13/110\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.7926 - accuracy: 0.7473\n",
            "Epoch 00013: val_loss improved from 0.92145 to 0.91662, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.8149 - accuracy: 0.7428 - val_loss: 0.9166 - val_accuracy: 0.7282\n",
            "Epoch 14/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7187 - accuracy: 0.7609\n",
            "Epoch 00014: val_loss did not improve from 0.91662\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7194 - accuracy: 0.7606 - val_loss: 0.9233 - val_accuracy: 0.7343\n",
            "Epoch 15/110\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.7587 - accuracy: 0.7554\n",
            "Epoch 00015: val_loss did not improve from 0.91662\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7587 - accuracy: 0.7554 - val_loss: 0.9352 - val_accuracy: 0.7276\n",
            "Epoch 16/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7403 - accuracy: 0.7604\n",
            "Epoch 00016: val_loss did not improve from 0.91662\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7391 - accuracy: 0.7606 - val_loss: 0.9396 - val_accuracy: 0.7230\n",
            "Epoch 17/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7586 - accuracy: 0.7477\n",
            "Epoch 00017: val_loss improved from 0.91662 to 0.89915, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7578 - accuracy: 0.7480 - val_loss: 0.8991 - val_accuracy: 0.7338\n",
            "Epoch 18/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.6882 - accuracy: 0.7693\n",
            "Epoch 00018: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7135 - accuracy: 0.7595 - val_loss: 0.9311 - val_accuracy: 0.7319\n",
            "Epoch 19/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7256 - accuracy: 0.7620\n",
            "Epoch 00019: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.7251 - accuracy: 0.7669 - val_loss: 0.9426 - val_accuracy: 0.7289\n",
            "Epoch 20/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.8005 - accuracy: 0.7467\n",
            "Epoch 00020: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.8062 - accuracy: 0.7423 - val_loss: 0.9447 - val_accuracy: 0.7232\n",
            "Epoch 21/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7657 - accuracy: 0.7487\n",
            "Epoch 00021: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7849 - accuracy: 0.7440 - val_loss: 0.9129 - val_accuracy: 0.7300\n",
            "Epoch 22/110\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.7300 - accuracy: 0.7655\n",
            "Epoch 00022: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7380 - accuracy: 0.7617 - val_loss: 0.9169 - val_accuracy: 0.7257\n",
            "Epoch 23/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7301 - accuracy: 0.7467\n",
            "Epoch 00023: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7311 - accuracy: 0.7526 - val_loss: 0.9385 - val_accuracy: 0.7265\n",
            "Epoch 24/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7658 - accuracy: 0.7546\n",
            "Epoch 00024: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7638 - accuracy: 0.7549 - val_loss: 0.9254 - val_accuracy: 0.7249\n",
            "Epoch 25/110\n",
            " 96/110 [=========================>....] - ETA: 0s - loss: 0.7836 - accuracy: 0.7507\n",
            "Epoch 00025: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7751 - accuracy: 0.7514 - val_loss: 0.9064 - val_accuracy: 0.7336\n",
            "Epoch 26/110\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.7515 - accuracy: 0.7601\n",
            "Epoch 00026: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7572 - accuracy: 0.7566 - val_loss: 0.9146 - val_accuracy: 0.7272\n",
            "Epoch 27/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7910 - accuracy: 0.7480\n",
            "Epoch 00027: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.7928 - accuracy: 0.7463 - val_loss: 0.9241 - val_accuracy: 0.7295\n",
            "Epoch 28/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.8477 - accuracy: 0.7280\n",
            "Epoch 00028: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.8564 - accuracy: 0.7285 - val_loss: 0.9120 - val_accuracy: 0.7283\n",
            "Epoch 29/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7395 - accuracy: 0.7517\n",
            "Epoch 00029: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7368 - accuracy: 0.7514 - val_loss: 0.9304 - val_accuracy: 0.7307\n",
            "Epoch 30/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7500 - accuracy: 0.7588\n",
            "Epoch 00030: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7464 - accuracy: 0.7589 - val_loss: 0.9345 - val_accuracy: 0.7328\n",
            "Epoch 31/110\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.7628 - accuracy: 0.7546\n",
            "Epoch 00031: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7823 - accuracy: 0.7577 - val_loss: 0.9475 - val_accuracy: 0.7269\n",
            "Epoch 32/110\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.7750 - accuracy: 0.7407\n",
            "Epoch 00032: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7783 - accuracy: 0.7394 - val_loss: 0.9367 - val_accuracy: 0.7376\n",
            "Epoch 33/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7158 - accuracy: 0.7646\n",
            "Epoch 00033: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7171 - accuracy: 0.7646 - val_loss: 0.9439 - val_accuracy: 0.7370\n",
            "Epoch 34/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7727 - accuracy: 0.7500\n",
            "Epoch 00034: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7721 - accuracy: 0.7503 - val_loss: 0.9211 - val_accuracy: 0.7378\n",
            "Epoch 35/110\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.7587 - accuracy: 0.7622\n",
            "Epoch 00035: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7699 - accuracy: 0.7589 - val_loss: 0.8995 - val_accuracy: 0.7428\n",
            "Epoch 36/110\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.7687 - accuracy: 0.7518\n",
            "Epoch 00036: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7639 - accuracy: 0.7526 - val_loss: 0.9377 - val_accuracy: 0.7263\n",
            "Epoch 37/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7860 - accuracy: 0.7402\n",
            "Epoch 00037: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7831 - accuracy: 0.7411 - val_loss: 0.9077 - val_accuracy: 0.7279\n",
            "Epoch 38/110\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.7737 - accuracy: 0.7527\n",
            "Epoch 00038: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7999 - accuracy: 0.7457 - val_loss: 0.9195 - val_accuracy: 0.7279\n",
            "Epoch 39/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7350 - accuracy: 0.7563\n",
            "Epoch 00039: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7351 - accuracy: 0.7560 - val_loss: 0.9171 - val_accuracy: 0.7302\n",
            "Epoch 40/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.7564\n",
            "Epoch 00040: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7440 - accuracy: 0.7572 - val_loss: 0.9124 - val_accuracy: 0.7287\n",
            "Epoch 41/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7572 - accuracy: 0.7482\n",
            "Epoch 00041: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7529 - accuracy: 0.7468 - val_loss: 0.9127 - val_accuracy: 0.7293\n",
            "Epoch 42/110\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.7871 - accuracy: 0.7439\n",
            "Epoch 00042: val_loss did not improve from 0.89915\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7807 - accuracy: 0.7446 - val_loss: 0.9114 - val_accuracy: 0.7332\n",
            "Epoch 43/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7671 - accuracy: 0.7452\n",
            "Epoch 00043: val_loss improved from 0.89915 to 0.88829, saving model to saved_models/audio_classification.hdf5\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7755 - accuracy: 0.7428 - val_loss: 0.8883 - val_accuracy: 0.7300\n",
            "Epoch 44/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7861 - accuracy: 0.7452\n",
            "Epoch 00044: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7718 - accuracy: 0.7514 - val_loss: 0.9194 - val_accuracy: 0.7322\n",
            "Epoch 45/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7712 - accuracy: 0.7467\n",
            "Epoch 00045: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7847 - accuracy: 0.7463 - val_loss: 0.9296 - val_accuracy: 0.7270\n",
            "Epoch 46/110\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.7245 - accuracy: 0.7590\n",
            "Epoch 00046: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7176 - accuracy: 0.7623 - val_loss: 0.9039 - val_accuracy: 0.7316\n",
            "Epoch 47/110\n",
            " 94/110 [========================>.....] - ETA: 0s - loss: 0.7587 - accuracy: 0.7553\n",
            "Epoch 00047: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7620 - accuracy: 0.7509 - val_loss: 0.9182 - val_accuracy: 0.7342\n",
            "Epoch 48/110\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.7642 - accuracy: 0.7446\n",
            "Epoch 00048: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7642 - accuracy: 0.7446 - val_loss: 0.9502 - val_accuracy: 0.7214\n",
            "Epoch 49/110\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.7653 - accuracy: 0.7491\n",
            "Epoch 00049: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7653 - accuracy: 0.7491 - val_loss: 0.9116 - val_accuracy: 0.7287\n",
            "Epoch 50/110\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.7649 - accuracy: 0.7577\n",
            "Epoch 00050: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7717 - accuracy: 0.7543 - val_loss: 0.9239 - val_accuracy: 0.7315\n",
            "Epoch 51/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7605 - accuracy: 0.7454\n",
            "Epoch 00051: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7596 - accuracy: 0.7457 - val_loss: 0.9092 - val_accuracy: 0.7328\n",
            "Epoch 52/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.8000 - accuracy: 0.7494\n",
            "Epoch 00052: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7982 - accuracy: 0.7486 - val_loss: 0.9119 - val_accuracy: 0.7328\n",
            "Epoch 53/110\n",
            " 92/110 [========================>.....] - ETA: 0s - loss: 0.8640 - accuracy: 0.7194\n",
            "Epoch 00053: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.8491 - accuracy: 0.7228 - val_loss: 0.9158 - val_accuracy: 0.7273\n",
            "Epoch 54/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7773 - accuracy: 0.7524\n",
            "Epoch 00054: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7797 - accuracy: 0.7532 - val_loss: 0.9131 - val_accuracy: 0.7330\n",
            "Epoch 55/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7452 - accuracy: 0.7494\n",
            "Epoch 00055: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.7469 - accuracy: 0.7480 - val_loss: 0.9406 - val_accuracy: 0.7296\n",
            "Epoch 56/110\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.7862 - accuracy: 0.7423\n",
            "Epoch 00056: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.7715 - accuracy: 0.7463 - val_loss: 0.9026 - val_accuracy: 0.7332\n",
            "Epoch 57/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.8225 - accuracy: 0.7413\n",
            "Epoch 00057: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.8185 - accuracy: 0.7428 - val_loss: 0.9149 - val_accuracy: 0.7255\n",
            "Epoch 58/110\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.7175 - accuracy: 0.7708\n",
            "Epoch 00058: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7134 - accuracy: 0.7721 - val_loss: 0.9078 - val_accuracy: 0.7266\n",
            "Epoch 59/110\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.7470 - accuracy: 0.7536\n",
            "Epoch 00059: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7515 - accuracy: 0.7537 - val_loss: 0.9222 - val_accuracy: 0.7269\n",
            "Epoch 60/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7635 - accuracy: 0.7517\n",
            "Epoch 00060: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7634 - accuracy: 0.7514 - val_loss: 0.9206 - val_accuracy: 0.7289\n",
            "Epoch 61/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7898 - accuracy: 0.7412\n",
            "Epoch 00061: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7905 - accuracy: 0.7411 - val_loss: 0.8938 - val_accuracy: 0.7322\n",
            "Epoch 62/110\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.7648 - accuracy: 0.7453\n",
            "Epoch 00062: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7654 - accuracy: 0.7451 - val_loss: 0.9280 - val_accuracy: 0.7212\n",
            "Epoch 63/110\n",
            " 97/110 [=========================>....] - ETA: 0s - loss: 0.7909 - accuracy: 0.7558\n",
            "Epoch 00063: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7922 - accuracy: 0.7503 - val_loss: 0.9080 - val_accuracy: 0.7289\n",
            "Epoch 64/110\n",
            "101/110 [==========================>...] - ETA: 0s - loss: 0.7367 - accuracy: 0.7673\n",
            "Epoch 00064: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7346 - accuracy: 0.7675 - val_loss: 0.9072 - val_accuracy: 0.7307\n",
            "Epoch 65/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7277 - accuracy: 0.7579\n",
            "Epoch 00065: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7243 - accuracy: 0.7600 - val_loss: 0.9171 - val_accuracy: 0.7305\n",
            "Epoch 66/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7354 - accuracy: 0.7588\n",
            "Epoch 00066: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.7331 - accuracy: 0.7595 - val_loss: 0.9198 - val_accuracy: 0.7289\n",
            "Epoch 67/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7717 - accuracy: 0.7379\n",
            "Epoch 00067: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7797 - accuracy: 0.7360 - val_loss: 0.9268 - val_accuracy: 0.7244\n",
            "Epoch 68/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7841 - accuracy: 0.7459\n",
            "Epoch 00068: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7823 - accuracy: 0.7463 - val_loss: 0.9171 - val_accuracy: 0.7229\n",
            "Epoch 69/110\n",
            " 95/110 [========================>.....] - ETA: 0s - loss: 0.6960 - accuracy: 0.7776\n",
            "Epoch 00069: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.6926 - accuracy: 0.7749 - val_loss: 0.9217 - val_accuracy: 0.7330\n",
            "Epoch 70/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7462 - accuracy: 0.7535\n",
            "Epoch 00070: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7443 - accuracy: 0.7532 - val_loss: 0.9707 - val_accuracy: 0.7302\n",
            "Epoch 71/110\n",
            "104/110 [===========================>..] - ETA: 0s - loss: 0.7280 - accuracy: 0.7572\n",
            "Epoch 00071: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7241 - accuracy: 0.7589 - val_loss: 0.9290 - val_accuracy: 0.7386\n",
            "Epoch 72/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7575 - accuracy: 0.7535\n",
            "Epoch 00072: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7604 - accuracy: 0.7514 - val_loss: 0.9478 - val_accuracy: 0.7292\n",
            "Epoch 73/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7884 - accuracy: 0.7529\n",
            "Epoch 00073: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7854 - accuracy: 0.7537 - val_loss: 0.9528 - val_accuracy: 0.7343\n",
            "Epoch 74/110\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.8062 - accuracy: 0.7408\n",
            "Epoch 00074: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7991 - accuracy: 0.7451 - val_loss: 0.9240 - val_accuracy: 0.7296\n",
            "Epoch 75/110\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.7401 - accuracy: 0.7509\n",
            "Epoch 00075: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7401 - accuracy: 0.7509 - val_loss: 0.9203 - val_accuracy: 0.7300\n",
            "Epoch 76/110\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.7866 - accuracy: 0.7471\n",
            "Epoch 00076: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7873 - accuracy: 0.7474 - val_loss: 0.9424 - val_accuracy: 0.7242\n",
            "Epoch 77/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7664 - accuracy: 0.7588\n",
            "Epoch 00077: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7614 - accuracy: 0.7595 - val_loss: 0.9186 - val_accuracy: 0.7328\n",
            "Epoch 78/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7309 - accuracy: 0.7653\n",
            "Epoch 00078: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7300 - accuracy: 0.7652 - val_loss: 0.9470 - val_accuracy: 0.7283\n",
            "Epoch 79/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7893 - accuracy: 0.7460\n",
            "Epoch 00079: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7905 - accuracy: 0.7457 - val_loss: 0.9033 - val_accuracy: 0.7345\n",
            "Epoch 80/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7980 - accuracy: 0.7488\n",
            "Epoch 00080: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7913 - accuracy: 0.7503 - val_loss: 0.9012 - val_accuracy: 0.7319\n",
            "Epoch 81/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7716 - accuracy: 0.7571\n",
            "Epoch 00081: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7766 - accuracy: 0.7554 - val_loss: 0.9239 - val_accuracy: 0.7253\n",
            "Epoch 82/110\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.7616 - accuracy: 0.7567\n",
            "Epoch 00082: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7538 - accuracy: 0.7589 - val_loss: 0.8992 - val_accuracy: 0.7330\n",
            "Epoch 83/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7293 - accuracy: 0.7587\n",
            "Epoch 00083: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7302 - accuracy: 0.7595 - val_loss: 0.9237 - val_accuracy: 0.7277\n",
            "Epoch 84/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7303 - accuracy: 0.7512\n",
            "Epoch 00084: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7292 - accuracy: 0.7509 - val_loss: 0.9323 - val_accuracy: 0.7285\n",
            "Epoch 85/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7419 - accuracy: 0.7579\n",
            "Epoch 00085: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7454 - accuracy: 0.7554 - val_loss: 0.9427 - val_accuracy: 0.7267\n",
            "Epoch 86/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7114 - accuracy: 0.7633\n",
            "Epoch 00086: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7107 - accuracy: 0.7640 - val_loss: 0.9192 - val_accuracy: 0.7309\n",
            "Epoch 87/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7544 - accuracy: 0.7624\n",
            "Epoch 00087: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7465 - accuracy: 0.7652 - val_loss: 0.9429 - val_accuracy: 0.7333\n",
            "Epoch 88/110\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.7901 - accuracy: 0.7600\n",
            "Epoch 00088: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7901 - accuracy: 0.7600 - val_loss: 0.9264 - val_accuracy: 0.7262\n",
            "Epoch 89/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7504 - accuracy: 0.7476\n",
            "Epoch 00089: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7507 - accuracy: 0.7509 - val_loss: 0.9204 - val_accuracy: 0.7309\n",
            "Epoch 90/110\n",
            " 93/110 [========================>.....] - ETA: 0s - loss: 0.7828 - accuracy: 0.7500\n",
            "Epoch 00090: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7951 - accuracy: 0.7468 - val_loss: 0.9271 - val_accuracy: 0.7396\n",
            "Epoch 91/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7497 - accuracy: 0.7588\n",
            "Epoch 00091: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7516 - accuracy: 0.7572 - val_loss: 0.9405 - val_accuracy: 0.7267\n",
            "Epoch 92/110\n",
            "108/110 [============================>.] - ETA: 0s - loss: 0.7834 - accuracy: 0.7431\n",
            "Epoch 00092: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7861 - accuracy: 0.7428 - val_loss: 0.9568 - val_accuracy: 0.7209\n",
            "Epoch 93/110\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.7336 - accuracy: 0.7538\n",
            "Epoch 00093: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7374 - accuracy: 0.7532 - val_loss: 0.9462 - val_accuracy: 0.7286\n",
            "Epoch 94/110\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.7224 - accuracy: 0.7675\n",
            "Epoch 00094: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7214 - accuracy: 0.7675 - val_loss: 0.9343 - val_accuracy: 0.7353\n",
            "Epoch 95/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7828 - accuracy: 0.7591\n",
            "Epoch 00095: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7832 - accuracy: 0.7600 - val_loss: 0.9589 - val_accuracy: 0.7242\n",
            "Epoch 96/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7027 - accuracy: 0.7743\n",
            "Epoch 00096: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7259 - accuracy: 0.7669 - val_loss: 0.9278 - val_accuracy: 0.7292\n",
            "Epoch 97/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7130 - accuracy: 0.7627\n",
            "Epoch 00097: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7132 - accuracy: 0.7635 - val_loss: 0.9380 - val_accuracy: 0.7252\n",
            "Epoch 98/110\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.7785 - accuracy: 0.7616\n",
            "Epoch 00098: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7963 - accuracy: 0.7560 - val_loss: 0.9468 - val_accuracy: 0.7265\n",
            "Epoch 99/110\n",
            "100/110 [==========================>...] - ETA: 0s - loss: 0.7515 - accuracy: 0.7619\n",
            "Epoch 00099: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7559 - accuracy: 0.7583 - val_loss: 0.9158 - val_accuracy: 0.7315\n",
            "Epoch 100/110\n",
            " 98/110 [=========================>....] - ETA: 0s - loss: 0.7683 - accuracy: 0.7417\n",
            "Epoch 00100: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7912 - accuracy: 0.7354 - val_loss: 0.9413 - val_accuracy: 0.7194\n",
            "Epoch 101/110\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.7876 - accuracy: 0.7454\n",
            "Epoch 00101: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7873 - accuracy: 0.7457 - val_loss: 0.9278 - val_accuracy: 0.7316\n",
            "Epoch 102/110\n",
            "110/110 [==============================] - ETA: 0s - loss: 0.7784 - accuracy: 0.7388\n",
            "Epoch 00102: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7784 - accuracy: 0.7388 - val_loss: 0.9052 - val_accuracy: 0.7328\n",
            "Epoch 103/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7286 - accuracy: 0.7565\n",
            "Epoch 00103: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7225 - accuracy: 0.7572 - val_loss: 0.9215 - val_accuracy: 0.7372\n",
            "Epoch 104/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7340 - accuracy: 0.7659\n",
            "Epoch 00104: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7295 - accuracy: 0.7658 - val_loss: 0.9115 - val_accuracy: 0.7340\n",
            "Epoch 105/110\n",
            "107/110 [============================>.] - ETA: 0s - loss: 0.7425 - accuracy: 0.7669\n",
            "Epoch 00105: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7431 - accuracy: 0.7663 - val_loss: 0.9303 - val_accuracy: 0.7317\n",
            "Epoch 106/110\n",
            "102/110 [==========================>...] - ETA: 0s - loss: 0.7556 - accuracy: 0.7500\n",
            "Epoch 00106: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7421 - accuracy: 0.7537 - val_loss: 0.9036 - val_accuracy: 0.7338\n",
            "Epoch 107/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7638 - accuracy: 0.7548\n",
            "Epoch 00107: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7493 - accuracy: 0.7589 - val_loss: 0.9323 - val_accuracy: 0.7247\n",
            "Epoch 108/110\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.7055 - accuracy: 0.7673\n",
            "Epoch 00108: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.6937 - accuracy: 0.7709 - val_loss: 0.9300 - val_accuracy: 0.7272\n",
            "Epoch 109/110\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.7571 - accuracy: 0.7453\n",
            "Epoch 00109: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.7570 - accuracy: 0.7463 - val_loss: 0.9327 - val_accuracy: 0.7280\n",
            "Epoch 110/110\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.7466 - accuracy: 0.7500\n",
            "Epoch 00110: val_loss did not improve from 0.88829\n",
            "110/110 [==============================] - 1s 10ms/step - loss: 0.7468 - accuracy: 0.7480 - val_loss: 0.9180 - val_accuracy: 0.7409\n",
            "Training completed in time:  0:02:24.726395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-udZLu4TWFBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzH3eZYSSKzK",
        "outputId": "55856087-1bb8-44de-e3b5-3c3b743ecd0f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7409104108810425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Minor Project/Saved Model/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RYjQasqSL1h",
        "outputId": "821a1e3b-640a-4b0f-b526-ead24c4fde00"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Minor Project/Saved Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qNeg-QzkW-BR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}